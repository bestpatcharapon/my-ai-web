import { useState, useEffect } from 'react';
import './VoiceButton.css';
import { FiMic, FiMicOff } from 'react-icons/fi';

function VoiceButton({ onTranscript, disabled }) {
  const [isListening, setIsListening] = useState(false);
  const [recognition, setRecognition] = useState(null);
  const [isSupported, setIsSupported] = useState(false);

  useEffect(() => {
    // ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ browser ‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö Speech Recognition ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      const recognitionInstance = new SpeechRecognition();
      
      recognitionInstance.continuous = false; // ‡∏´‡∏¢‡∏∏‡∏î‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
      recognitionInstance.interimResults = true; // ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏û‡∏π‡∏î
      recognitionInstance.lang = 'th-TH'; // ‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡∏´‡∏•‡∏±‡∏Å
      
      recognitionInstance.onresult = (event) => {
        const transcript = Array.from(event.results)
          .map(result => result[0])
          .map(result => result.transcript)
          .join('');
        
        console.log('üé§ Voice transcript:', transcript);
        
        if (onTranscript) {
          onTranscript(transcript);
        }
      };
      
      recognitionInstance.onerror = (event) => {
        console.error('Speech recognition error:', event.error);
        
        let errorMessage = '‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡∏Ñ‡πå‡πÑ‡∏î‡πâ';
        if (event.error === 'network') {
          errorMessage = '‚ö†Ô∏è ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£ internet connection ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡πÑ‡∏°‡∏Ñ‡πå';
        } else if (event.error === 'not-allowed') {
          errorMessage = '‚ö†Ô∏è ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡πÉ‡∏´‡πâ‡πÉ‡∏ä‡πâ‡πÑ‡∏°‡∏Ñ‡πå‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ browser';
        }
        
        alert(errorMessage);
        setIsListening(false);
      };
      
      recognitionInstance.onend = () => {
        setIsListening(false);
      };
      
      setRecognition(recognitionInstance);
      setIsSupported(true);
    } else {
      console.warn('Speech Recognition not supported in this browser');
      setIsSupported(false);
    }
  }, [onTranscript]);

  const toggleListening = () => {
    if (!recognition) return;
    
    if (isListening) {
      console.log('üõë Stopping voice recognition');
      recognition.stop();
      setIsListening(false);
    } else {
      console.log('‚ñ∂Ô∏è Starting voice recognition...');
      try {
        recognition.start();
        setIsListening(true);
      } catch (error) {
        console.error('Failed to start recognition:', error);
      }
    }
  };

  // ‡∏ñ‡πâ‡∏≤ browser ‡πÑ‡∏°‡πà‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö ‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏∏‡πà‡∏°
  if (!isSupported) {
    return null;
  }

  return (
    <button
      type="button"
      className={`voice-btn ${isListening ? 'listening' : ''}`}
      onClick={toggleListening}
      disabled={disabled}
      title={isListening ? '‡∏´‡∏¢‡∏∏‡∏î‡∏ü‡∏±‡∏á' : '‡∏û‡∏π‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏¥‡∏°‡∏û‡πå'}
    >
      {isListening ? <FiMicOff size={22} /> : <FiMic size={22} />}
      {isListening && <span className="pulse-ring"></span>}
    </button>
  );
}

export default VoiceButton;
